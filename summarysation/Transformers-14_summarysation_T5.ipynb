{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf0a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: gazeta/default\n",
      "Found cached dataset gazeta (/home/medic/.cache/huggingface/datasets/IlyaGusev___gazeta/default/1.0.0/ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457)\n",
      "No config specified, defaulting to: gazeta/default\n",
      "Found cached dataset gazeta (/home/medic/.cache/huggingface/datasets/IlyaGusev___gazeta/default/1.0.0/ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_train = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\", split= 'train[:10%]')\n",
    "dataset_test = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\", split= 'test[:10%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5483df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "    num_rows: 5240\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c56b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbcba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_tok(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207e96c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_sum, max_len_tl = max(map(len_tok, dataset_train['summary'])), max(map(len_tok, dataset_train['title']))\n",
    "max_len_sum, max_len_tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37fcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_sum, max_len_tl = 60, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4049874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/medic/.cache/huggingface/datasets/IlyaGusev___gazeta/default/1.0.0/ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457/cache-2cf81f28446bb4c6.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16ae8c4336341e2b11ba0f6bf6699bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_input = tokenizer(batch['summary'], padding='max_length', truncation=True, max_length=max_len_sum)\n",
    "    tokenized_label = tokenizer(batch['title'], padding='max_length', truncation=True, max_length=max_len_tl)\n",
    "\n",
    "    tokenized_input['labels'] = tokenized_label['input_ids']\n",
    "\n",
    "    return tokenized_input\n",
    "\n",
    "dataset_train = dataset_train.map(tokenize, batched=True, batch_size=8)\n",
    "dataset_test = dataset_test.map(tokenize, batched=True, batch_size=8)\n",
    "\n",
    "dataset_train.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dataset_test.set_format('numpy', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57413b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.save_to_disk('gazeta/train')\n",
    "dataset_test.save_to_disk('gazeta/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c02be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cb25ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'gazeta/output'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_accumulation_steps=1, # Number of eval steps to keep in GPU (the higher, the mor vRAM used)\n",
    "    prediction_loss_only=True, # If I need co compute only loss and not other metrics, setting this to true will use less RAM\n",
    "    learning_rate=0.00001,\n",
    "    evaluation_strategy='steps', # Run evaluation every eval_steps\n",
    "    save_steps=1000, # How often to save a checkpoint\n",
    "    save_total_limit=1, # Number of maximum checkpoints to save\n",
    "    remove_unused_columns=True, # Removes useless columns from the dataset\n",
    "    run_name='run_gazeta', # Wandb run name\n",
    "    logging_steps=500, # How often to log loss to wandb\n",
    "    eval_steps=500, # How often to run evaluation on the val_set\n",
    "    logging_first_step=False, # Whether to log also the very first training step to wandb\n",
    "    load_best_model_at_end=True, # Whether to load the best model found at each evaluation.\n",
    "    metric_for_best_model=\"loss\", # Use loss to evaluate best model.\n",
    "    greater_is_better=False # Best model is the one with the lowest loss, not highest.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39c20226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/medic/python310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5240\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32750\n",
      "  Number of trainable parameters = 244309248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32750' max='32750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32750/32750 1:58:30, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.294500</td>\n",
       "      <td>2.800131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.299200</td>\n",
       "      <td>2.785827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.214100</td>\n",
       "      <td>2.765320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.194500</td>\n",
       "      <td>2.747967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.159600</td>\n",
       "      <td>2.754606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.145500</td>\n",
       "      <td>2.760347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.119700</td>\n",
       "      <td>2.737623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.147900</td>\n",
       "      <td>2.732628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.100400</td>\n",
       "      <td>2.725555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.118700</td>\n",
       "      <td>2.707140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.109500</td>\n",
       "      <td>2.734493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.095100</td>\n",
       "      <td>2.728151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.069600</td>\n",
       "      <td>2.706535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.059700</td>\n",
       "      <td>2.718879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.038400</td>\n",
       "      <td>2.710202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.027700</td>\n",
       "      <td>2.708791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.998700</td>\n",
       "      <td>2.725571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.989400</td>\n",
       "      <td>2.714880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.959100</td>\n",
       "      <td>2.714424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.968400</td>\n",
       "      <td>2.725327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.943400</td>\n",
       "      <td>2.707914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.924900</td>\n",
       "      <td>2.716844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.914200</td>\n",
       "      <td>2.722234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.904300</td>\n",
       "      <td>2.725193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.875800</td>\n",
       "      <td>2.732715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.891500</td>\n",
       "      <td>2.739643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.850700</td>\n",
       "      <td>2.738489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.861100</td>\n",
       "      <td>2.747176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.835100</td>\n",
       "      <td>2.732473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.828600</td>\n",
       "      <td>2.748757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.828600</td>\n",
       "      <td>2.757701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.811000</td>\n",
       "      <td>2.746471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.800200</td>\n",
       "      <td>2.754670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.807400</td>\n",
       "      <td>2.762847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.781800</td>\n",
       "      <td>2.778518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.774400</td>\n",
       "      <td>2.760081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.775400</td>\n",
       "      <td>2.749391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.766900</td>\n",
       "      <td>2.757965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>1.753300</td>\n",
       "      <td>2.762342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.745700</td>\n",
       "      <td>2.762413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>1.759700</td>\n",
       "      <td>2.773782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.733200</td>\n",
       "      <td>2.781695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>1.719100</td>\n",
       "      <td>2.777317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.730700</td>\n",
       "      <td>2.780853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>1.703600</td>\n",
       "      <td>2.783885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.722800</td>\n",
       "      <td>2.784200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>1.707100</td>\n",
       "      <td>2.778044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.696000</td>\n",
       "      <td>2.774055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>1.701900</td>\n",
       "      <td>2.788348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.701800</td>\n",
       "      <td>2.790556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>1.685500</td>\n",
       "      <td>2.787069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.681700</td>\n",
       "      <td>2.786190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>1.685600</td>\n",
       "      <td>2.786272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.682300</td>\n",
       "      <td>2.783427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>1.676000</td>\n",
       "      <td>2.783958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.671600</td>\n",
       "      <td>2.792235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>1.676900</td>\n",
       "      <td>2.796650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.656600</td>\n",
       "      <td>2.794501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>1.661700</td>\n",
       "      <td>2.794154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.676400</td>\n",
       "      <td>2.800705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>1.669800</td>\n",
       "      <td>2.799136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.656100</td>\n",
       "      <td>2.795333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>1.673600</td>\n",
       "      <td>2.796373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.661100</td>\n",
       "      <td>2.796642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>1.668700</td>\n",
       "      <td>2.798140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-1000\n",
      "Configuration saved in gazeta/output/checkpoint-1000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-2000\n",
      "Configuration saved in gazeta/output/checkpoint-2000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-3000\n",
      "Configuration saved in gazeta/output/checkpoint-3000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-3000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-4000\n",
      "Configuration saved in gazeta/output/checkpoint-4000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-5000\n",
      "Configuration saved in gazeta/output/checkpoint-5000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-6000\n",
      "Configuration saved in gazeta/output/checkpoint-6000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-6000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-7000\n",
      "Configuration saved in gazeta/output/checkpoint-7000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-8000\n",
      "Configuration saved in gazeta/output/checkpoint-8000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-9000\n",
      "Configuration saved in gazeta/output/checkpoint-9000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-10000\n",
      "Configuration saved in gazeta/output/checkpoint-10000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-9000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-11000\n",
      "Configuration saved in gazeta/output/checkpoint-11000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-10000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-12000\n",
      "Configuration saved in gazeta/output/checkpoint-12000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-11000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-13000\n",
      "Configuration saved in gazeta/output/checkpoint-13000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-12000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-14000\n",
      "Configuration saved in gazeta/output/checkpoint-14000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-13000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-15000\n",
      "Configuration saved in gazeta/output/checkpoint-15000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-14000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-16000\n",
      "Configuration saved in gazeta/output/checkpoint-16000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-15000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-17000\n",
      "Configuration saved in gazeta/output/checkpoint-17000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-16000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-18000\n",
      "Configuration saved in gazeta/output/checkpoint-18000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-17000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-19000\n",
      "Configuration saved in gazeta/output/checkpoint-19000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-18000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-20000\n",
      "Configuration saved in gazeta/output/checkpoint-20000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-19000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-21000\n",
      "Configuration saved in gazeta/output/checkpoint-21000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-20000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-22000\n",
      "Configuration saved in gazeta/output/checkpoint-22000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-21000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-23000\n",
      "Configuration saved in gazeta/output/checkpoint-23000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-22000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-24000\n",
      "Configuration saved in gazeta/output/checkpoint-24000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-23000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-25000\n",
      "Configuration saved in gazeta/output/checkpoint-25000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-24000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-26000\n",
      "Configuration saved in gazeta/output/checkpoint-26000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-25000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-27000\n",
      "Configuration saved in gazeta/output/checkpoint-27000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-26000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-28000\n",
      "Configuration saved in gazeta/output/checkpoint-28000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-27000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-29000\n",
      "Configuration saved in gazeta/output/checkpoint-29000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-28000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-30000\n",
      "Configuration saved in gazeta/output/checkpoint-30000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-29000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-31000\n",
      "Configuration saved in gazeta/output/checkpoint-31000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-30000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to gazeta/output/checkpoint-32000\n",
      "Configuration saved in gazeta/output/checkpoint-32000/config.json\n",
      "Model weights saved in gazeta/output/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-31000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: text, title, url, summary, date. If text, title, url, summary, date are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 577\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from gazeta/output/checkpoint-5000 (score: 2.7071404457092285).\n",
      "Deleting older checkpoint [gazeta/output/checkpoint-32000] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32750, training_loss=1.860656222976801, metrics={'train_runtime': 7110.3511, 'train_samples_per_second': 36.848, 'train_steps_per_second': 4.606, 'total_flos': 2.08700430336e+16, 'train_loss': 1.860656222976801, 'epoch': 50.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d5675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to gazeta/output/model\n",
      "Configuration saved in gazeta/output/model/config.json\n",
      "Model weights saved in gazeta/output/model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1305484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: | Торговое перемирие между США и Китаем вполне возможно. Китай согласился на уступки в сельхозсекторе, а США ослабят тарифную политику. Такое заключение можно сделать по итогам диалога сторон в Вашингтоне в пятницу. Президент Дональд Трамп назвал переговоры «значительной первой фазой» будущей торговой сделки, которую он планирует подписать с председателем Си Цзиньпином в декабре. Впрочем, эта «первая фаза» не затрагивает других острых споров между державами.\n",
      "TITLE: | «Первая фаза»: США и Китай закончат войну?\n"
     ]
    }
   ],
   "source": [
    "INX = 457\n",
    "print(\"SUMMARY: | {}\".format(dataset_test['summary'][INX]))\n",
    "print(\"TITLE: | {}\".format(dataset_test['title'][INX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c63250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03426e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output:\n",
      "Китай согласился на перемирие\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_text = dataset_test['summary'][INX]\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokenized_text = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    source_ids = tokenized_text['input_ids'].to(device, dtype = torch.long)\n",
    "    source_mask = tokenized_text['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids = source_ids,\n",
    "        attention_mask = source_mask, \n",
    "        max_length=512,\n",
    "        num_beams=7,\n",
    "        temperature = 1.3,\n",
    "        repetition_penalty=1, \n",
    "        length_penalty=1, \n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=1\n",
    "    )\n",
    "\n",
    "    pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(\"\\noutput:\\n\" + pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
