{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7d8c0f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/medic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import natasha\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NamesExtractor,\n",
    "    NewsNERTagger,\n",
    "    PER,\n",
    "    Doc\n",
    ")\n",
    "import eli5\n",
    "from navec import Navec\n",
    "from slovnet import NER\n",
    "from ipymarkup import show_span_box_markup as show_markup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import chain\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_ru = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "012979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('./test_hotels.xlsx')\n",
    "train_data = pd.read_excel('./train_hotels.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb4e078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for create classes in our dataset \n",
    "def create_sentiment(x):\n",
    "    sentiment = 0\n",
    "    if x > 3:\n",
    "        sentiment = 1\n",
    "    else:\n",
    "        sentiment = 0\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "194bc9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'] = train_data.apply(lambda x: create_sentiment(x['sentiment']), axis = 1)\n",
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c1762846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentiment'] = test_data.apply(lambda x: create_sentiment(x['sentiment']), axis = 1)\n",
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4a2dd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear Nan data in datasets\n",
    "train_data.dropna(subset = ['text'], inplace = True)\n",
    "test_data.dropna(subset = ['text'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5e94f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50175 entries, 0 to 50327\n",
      "Data columns (total 3 columns):\n",
      "sentiment    50175 non-null int64\n",
      "text         50175 non-null object\n",
      "predict      50175 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6876 entries, 0 to 6875\n",
      "Data columns (total 2 columns):\n",
      "sentiment    6876 non-null int64\n",
      "text         6876 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 161.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.info(), test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e2eea",
   "metadata": {},
   "source": [
    "#### Начнем классификацию текстов. \n",
    "Первым попробуем наивный подход - проверка в тексте слов характеных для положительных отзывов, и соотвественно отрицательных. \n",
    "Составим массив положительных и отрицательных слов для нашей \"наивной\" классификации.\n",
    "Воспользуемся CountVectorizer замечательной библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0904b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    new_text = text.lower()\n",
    "    new_text = [word for word in new_text.split() if len(word) > 1]\n",
    "    new_text = [word for word in new_text if word not in stopwords_ru]\n",
    "    new_text = [re.sub(r'[^\\w\\s]', '', word) for word in new_text]\n",
    "    new_text = [re.sub(r'[^а-яА-Я0-9]', '', word) for word in new_text]\n",
    "    new_text = [re.sub(r'[^а-яА-Я]', '', word) for word in new_text]\n",
    "    new_text = []\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "88f42394",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_list = [word for word in list(train_data['text'][train_data['sentiment'] == 0])]\n",
    "negative_list = clean_text(negative_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6460631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most freq negative words\n",
    "count_vectorizer_neg = CountVectorizer()\n",
    "counts_neg = count_vectorizer_neg.fit_transform(negative_list)\n",
    "negative_words = count_vectorizer_neg.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bbccdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most freq positive words\n",
    "positive_list = [word for word in list(train_data['text'][train_data['sentiment'] == 1])]\n",
    "positive_list = clean_text(positive_list[0])\n",
    "\n",
    "count_vectorizer_pos = CountVectorizer()\n",
    "counts_pos = count_vectorizer_pos.fit_transform(positive_list)\n",
    "positive_words = count_vectorizer_pos.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5eaf18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(set(positive_list) - set(negative_list))\n",
    "positive_list = list(set(positive_list) - set(diff))\n",
    "negative_list = list(set(negative_list) - set(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3a4038f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['автобусе',\n",
       "  'бассейном',\n",
       "  'брали',\n",
       "  'быстро',\n",
       "  'добраться',\n",
       "  'достаточно',\n",
       "  'достойный',\n",
       "  'завтраки',\n",
       "  'займет',\n",
       "  'интернетом',\n",
       "  'крыше',\n",
       "  'метро',\n",
       "  'минут',\n",
       "  'могу',\n",
       "  'номерами',\n",
       "  'отель',\n",
       "  'очень',\n",
       "  'пешком',\n",
       "  'поэтому',\n",
       "  'прекрасной',\n",
       "  'прекрасными',\n",
       "  'прогулка',\n",
       "  'сказать',\n",
       "  'террасой',\n",
       "  'уборкой',\n",
       "  'хорошим',\n",
       "  'центра'],\n",
       " ['автомобильную',\n",
       "  'ад',\n",
       "  'администратора',\n",
       "  'бассейн',\n",
       "  'бассейноми',\n",
       "  'берет',\n",
       "  'берут',\n",
       "  'бокала',\n",
       "  'большим',\n",
       "  'видами',\n",
       "  'вина',\n",
       "  'воздух',\n",
       "  'вход',\n",
       "  'вызвать',\n",
       "  'выходят',\n",
       "  'далеко',\n",
       "  'двумя',\n",
       "  'деньги',\n",
       "  'дом',\n",
       "  'дорогу',\n",
       "  'евро',\n",
       "  'закрытым',\n",
       "  'зал',\n",
       "  'звонок',\n",
       "  'зона',\n",
       "  'коекак',\n",
       "  'которые',\n",
       "  'минутпросьба',\n",
       "  'мыли',\n",
       "  'мыльных'])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words[:30], negative_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd76f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_negative_or_positiv(text):\n",
    "    positives = sum(word in text for word in positive_words)\n",
    "    negatives = sum(word in text for word in negative_words)\n",
    "    \n",
    "    if positives > negatives:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb7a7077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data['text'][3:4]\n",
    "choice_negative_or_positiv(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "56e27ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['predict'] = train_data.apply(lambda x: choice_negative_or_positiv(x['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cbe65c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18282012954658694"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(list(train_data['sentiment']), list(train_data['predict']))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b23f2",
   "metadata": {},
   "source": [
    "Мы получили совсем плохой результат. Давайте попробуем его улучшить уже с помощью методик машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3edb9",
   "metadata": {},
   "source": [
    "### LogisticRegression \n",
    "попробуем самую простую модель logistirRegression из библиотеки sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "46d75683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medic/python36/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model_lr = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
    "\n",
    "model_lr.fit(train_data['text'], train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "47bc767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913612565445026"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred = model_lr.predict(test_data['text'])\n",
    "lr_res = accuracy_score(test_data['sentiment'], lr_pred)\n",
    "lr_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68df9ed",
   "metadata": {},
   "source": [
    "Как всегда, простая модель логистической регрессии показывает очень хороший результат. С таким результататом уже можно работать и показывать хорошие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc24a9",
   "metadata": {},
   "source": [
    "Посмотрим на наши что же попадает у нас в положительные и что в отрицательные отзывы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d03dd7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.808\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        современная\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.669\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        приличная\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.600\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        непосредственной\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.576\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        рекомендуем\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.03%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.469\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        довольны\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.460\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.453\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        благодарность\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.430\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        устали\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.418\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        впечатляет\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.417\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        устраивает\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.397\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        замечательный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.386\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        белоснежное\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.385\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        тремя\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.364\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        чудесный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.362\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ужины\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.84%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 90112 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.94%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 44492 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.349\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        отвалилась\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.352\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        сауне\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.362\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        получше\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.366\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ногой\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.367\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        темная\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.398\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        грохот\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.399\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        неудобный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.409\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ужасное\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.410\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        понимают\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.414\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        начинают\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.03%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.468\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        испорчено\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.485\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        тянет\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.495\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        пойдет\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.75%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.505\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        отвратительное\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.563\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        скудные\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.599\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        грязный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.625\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        грязное\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.642\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ужасный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.645\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        разочарование\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.679\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        уставший\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.828\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        грязно\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.873\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ужасные\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.944\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ужасная\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.999\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        обшарпанный\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.025\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        грязные\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(classifier,  vec = vectorizer, top = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b1590",
   "metadata": {},
   "source": [
    "Отличное разделение!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d967219",
   "metadata": {},
   "source": [
    "Теперь можно попробовать сделать тоже самое но уже с учетом частоты встречаемости слов. Так слова в тексте встречаются с разной частотой - какие-то чаще, какие-то реже, следовательно у них будут разные веса, и это тоже можно учитывать в нашей модели. Для того чтобы учитывать частоту встречаемости слов можно использовать TfidVecrorizer из все той же библиотеки sklearn. Заменим CountVecrorizer на TfidVecrorizer и проведем новое обучение и проверим результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "234f1aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medic/python36/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9006689936009308"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer()\n",
    "classifier2 = LogisticRegression()\n",
    "\n",
    "model_lr2 = Pipeline([('vectorizer', vectorizer2), ('classifier', classifier2)])\n",
    "\n",
    "model_lr2.fit(train_data['text'], train_data['sentiment'])\n",
    "\n",
    "lr_pred2 = model_lr2.predict(test_data['text'])\n",
    "lr_res2 = accuracy_score(test_data['sentiment'], lr_pred2)\n",
    "lr_res2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948e2a4",
   "metadata": {},
   "source": [
    "Теперь можно подключить контекст. В качестве иструмента для работы с контекстом можно использовать n-gram слов,\n",
    "чтобы модель смотрела не отдельное слово а на их сочание. В некоторых случаях это сильно может сказаться\n",
    "на конечно результате."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c7c87",
   "metadata": {},
   "source": [
    "Попробуем добавить ngram из двух слов в нашу новую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8cd7c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8979057591623036"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3 = TfidfVectorizer(ngram_range=(1,2))\n",
    "classifier3 = LogisticRegression()\n",
    "\n",
    "model_lr3 = Pipeline([('vectorizer', vectorizer3), ('classifier', classifier3)])\n",
    "\n",
    "model_lr3.fit(train_data['text'], train_data['sentiment'])\n",
    "\n",
    "lr_pred3 = model_lr3.predict(test_data['text'])\n",
    "lr_res3 = accuracy_score(test_data['sentiment'], lr_pred3)\n",
    "lr_res3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab0e6f",
   "metadata": {},
   "source": [
    "Результат стал немного лучше, подход с изменением количества слов в векторизации имеет место быть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa0692",
   "metadata": {},
   "source": [
    "Еще один поход - брать не g-граммы слов, а n-граммы симолово от слов. Попробуем этот поход на той же схеме vectorizer и classifier добавив параметры analyzer = 'char'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "997b7a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999418266433973"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer4 = TfidfVectorizer(analyzer = 'char', ngram_range=(1,6), max_features = 40000)\n",
    "classifier4 = LogisticRegression()\n",
    "\n",
    "model_lr4 = Pipeline([('vectorizer', vectorizer4), ('classifier', classifier4)])\n",
    "\n",
    "model_lr4.fit(train_data['text'], train_data['sentiment'])\n",
    "\n",
    "lr_pred4 = model_lr4.predict(test_data['text'])\n",
    "lr_res4 = accuracy_score(test_data['sentiment'], lr_pred4)\n",
    "lr_res4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed5a03",
   "metadata": {},
   "source": [
    "#### Лематтизация \n",
    "Лемматизация позволяет нам приводить слова к нормальной форме. Проверим, влияет ли лемматизация на результат обучения и предсказания модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d21a55",
   "metadata": {},
   "source": [
    "Добавим в наш дата фрейм колонку с лемматизированным текстом, и поробуем обучение и предсказание на этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c59302f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lib natasha for create lemmatizer and lemmatize word in our dataset\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "name_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "15f8a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    output = []\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    for _ in doc.tokens:\n",
    "        if (len(_.lemma) > 2) and (_.lemma not in stopwords_ru):\n",
    "            output.append(_.lemma)\n",
    "    \n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e6226f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lemmatize_text'] = train_data.apply(lambda x: lemmatization(x['text']), axis = 1)\n",
    "test_data['lemmatize_text'] = test_data.apply(lambda x: lemmatization(x['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "76a994d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "      <th>lemmatize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Очень достойный отель с прекрасными номерами, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>очень достойный отель прекрасный номер хороший...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Остановились в Барселоне проездом, т.к. нужно ...</td>\n",
       "      <td>0</td>\n",
       "      <td>остановиться барселона проезд нужный посетить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Типичная сетевая гостиница. Главный плюс-шикар...</td>\n",
       "      <td>0</td>\n",
       "      <td>типичный сетевой гостиница главный плюс-шикарн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Начнем с того, что в этом отеле не берут деньг...</td>\n",
       "      <td>0</td>\n",
       "      <td>начать отель брать деньга воздух звонок телефо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Отель находится в отдалении от центра,но пешко...</td>\n",
       "      <td>0</td>\n",
       "      <td>отель находиться отдаление центр пешком дойти ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50323</th>\n",
       "      <td>1</td>\n",
       "      <td>Была в этом отеле всего одни сутки в конце пое...</td>\n",
       "      <td>0</td>\n",
       "      <td>отель сутки конец поездка отель понравиться бе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50324</th>\n",
       "      <td>0</td>\n",
       "      <td>Местоположение отличное. Сервис хороший. Завтр...</td>\n",
       "      <td>0</td>\n",
       "      <td>местоположение отличный сервис хороший завтрак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50325</th>\n",
       "      <td>1</td>\n",
       "      <td>Отдыхали вдвоем с мужем в январе 2015. Отель п...</td>\n",
       "      <td>0</td>\n",
       "      <td>отдыхать вдвоем муж январь 2015 отель понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50326</th>\n",
       "      <td>1</td>\n",
       "      <td>Отдыхали с друзьями впятером. Больше всего пон...</td>\n",
       "      <td>0</td>\n",
       "      <td>отдыхать друг впятером весь понравиться террит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50327</th>\n",
       "      <td>1</td>\n",
       "      <td>Отель вполне хорош. Были в низкий сезон в конц...</td>\n",
       "      <td>0</td>\n",
       "      <td>отель вполне хороший низкий сезон конец июнь в...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                               text  predict  \\\n",
       "0              1  Очень достойный отель с прекрасными номерами, ...        1   \n",
       "1              1  Остановились в Барселоне проездом, т.к. нужно ...        0   \n",
       "2              1  Типичная сетевая гостиница. Главный плюс-шикар...        0   \n",
       "3              0  Начнем с того, что в этом отеле не берут деньг...        0   \n",
       "4              1  Отель находится в отдалении от центра,но пешко...        0   \n",
       "...          ...                                                ...      ...   \n",
       "50323          1  Была в этом отеле всего одни сутки в конце пое...        0   \n",
       "50324          0  Местоположение отличное. Сервис хороший. Завтр...        0   \n",
       "50325          1  Отдыхали вдвоем с мужем в январе 2015. Отель п...        0   \n",
       "50326          1  Отдыхали с друзьями впятером. Больше всего пон...        0   \n",
       "50327          1  Отель вполне хорош. Были в низкий сезон в конц...        0   \n",
       "\n",
       "                                          lemmatize_text  \n",
       "0      очень достойный отель прекрасный номер хороший...  \n",
       "1      остановиться барселона проезд нужный посетить ...  \n",
       "2      типичный сетевой гостиница главный плюс-шикарн...  \n",
       "3      начать отель брать деньга воздух звонок телефо...  \n",
       "4      отель находиться отдаление центр пешком дойти ...  \n",
       "...                                                  ...  \n",
       "50323  отель сутки конец поездка отель понравиться бе...  \n",
       "50324  местоположение отличный сервис хороший завтрак...  \n",
       "50325  отдыхать вдвоем муж январь 2015 отель понравит...  \n",
       "50326  отдыхать друг впятером весь понравиться террит...  \n",
       "50327  отель вполне хороший низкий сезон конец июнь в...  \n",
       "\n",
       "[50175 rows x 4 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "321ebff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "train_data.to_pickle('train_data_hotels.pickle')\n",
    "test_data.to_pickle('test_data_hotels.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6e3f885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medic/python36/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9029959278650378"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regresion in lemmatisation\n",
    "vectorizer_lem = TfidfVectorizer()\n",
    "classifier_lem = LogisticRegression()\n",
    "\n",
    "model_lem = Pipeline([('vectorizer', vectorizer_lem), ('classifier', classifier_lem)])\n",
    "\n",
    "model_lem.fit(train_data['lemmatize_text'], train_data['sentiment'])\n",
    "\n",
    "lr_pred_lem = model_lem.predict(test_data['lemmatize_text'])\n",
    "lr_res_lem = accuracy_score(test_data['sentiment'], lr_pred_lem)\n",
    "lr_res_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ab4bf",
   "metadata": {},
   "source": [
    "лемматизация помогла еще повысить наш  результат на несколько процентных пунктов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65c3f13",
   "metadata": {},
   "source": [
    "Попробуем еще одну технику из NLP приема - заменим распознанные сущности NER на их теги и посмотрим на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "11c49959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_search(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    for span in doc.spans:\n",
    "        text = text.replace(span.text, span.type)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "506eea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text_NER'] = train_data.apply(lambda x: ner_search(x['text']), axis = 1)\n",
    "test_data['text_NER'] = test_data.apply(lambda x: ner_search(x['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "42ae8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medic/python36/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9013961605584643"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regresion in NER tags\n",
    "vectorizer_ner = TfidfVectorizer()\n",
    "classifier_ner = LogisticRegression()\n",
    "\n",
    "model_ner = Pipeline([('vectorizer', vectorizer_ner), ('classifier', classifier_ner)])\n",
    "\n",
    "model_ner.fit(train_data['text_NER'], train_data['sentiment'])\n",
    "\n",
    "lr_pred_ner = model_ner.predict(test_data['text_NER'])\n",
    "lr_res_ner = accuracy_score(test_data['sentiment'], lr_pred_ner)\n",
    "lr_res_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b0217",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <head>\n",
    "        <tr >\n",
    "            <td>№</td>\n",
    "            <td>Модель</td>   \n",
    "            <td>Результат (accuracy)</td>\n",
    "        </tr>\n",
    "    </head>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>\"Наивная модель\" - просто взяли слова из текста и посчитали их количество</td>\n",
    "        <td>0.18</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>Простая LogicRegression - обычный CountVectorizer() без дополнительных параметров </td>\n",
    "        <td>0.891361</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>Простая LogicRegression - TfidfVectorizer() учитывающий частоту встречающихся слов</td>\n",
    "        <td>0.900668</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>Простая LogicRegression - TfidfVectorizer() c n-gramm в два слова</td>\n",
    "        <td>0.900668</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td>\n",
    "        <td>Простая LogicRegression - TfidfVectorizer() с n-gramm из символов</td>\n",
    "        <td>0.899941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>6</td>\n",
    "        <td>Простая LogicRegression - TfidfVectorizer() c lemmatizer из библиотеке natasha</td>\n",
    "        <td>0.902995</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>7</td>\n",
    "        <td>Простая LogicRegression - TfidfVectorizer() c NER типом токена вместо вместо самих токенов</td>\n",
    "        <td>0.901396</td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f719408",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "1. Наивный подход ожидаемо работает хуже всех. Однако тут есть поле для улучшения результата. И при достаточном количестве времени результ можно поднять до 0.6 а может быть даже и выше.\n",
    "2. Не плохой результат показал самый просто ML метод с простым CountVectorizer. Впрочем, как обычно, простые классические методы ML за частую показывают результаты не хуче чем новые методы основанные на нейронка и тербующие большие мощности для своей работы.\n",
    "3. Лучший результат показала LR с лемматизацией. Результат закономерен так как тут мы получаем наиболее чистые данные для модели.\n",
    "4. На втором месте по точности определения модель LR с данными в которых заменили определенные перед этим NER сущности и заменили их на обочнающие их типы.\n",
    "5. Для русского языка лучше рабоет модель c n-gramm для нескольких слов, чем n-gramm для символов. Вот такая особенность у русского языка, в английском языке бывает наоборот. Ну там и стеммизация работает не плохо, которая в русском языке не работает совсем."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
