{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[K     |████████████████████████████████| 772 kB 30.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.4)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 1.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Installing collected packages: tqdm, pyyaml, filelock, huggingface-hub, tokenizers, regex, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.11.1 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.25.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers[sentencepiece]) (2.22.0)\n",
      "Requirement already satisfied: protobuf<=3.20.2; extra == \"sentencepiece\" in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91; extra == \"sentencepiece\"\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]) (4.4.0)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers \n",
    "Попробуем трансформеры в машинном переводе.\n",
    "Возьмем самый простой пример, с готовой обученной моделью. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Hallo Welt, das ist Roboter, und es wäre zu zeigen, dass es richtig tun!'}]\n",
      "CPU times: user 1min 1s, sys: 5.2 s, total: 1min 6s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "translator = pipeline('translation_en_to_de')\n",
    "text = 'Hello world! This is robot, and it would be show that do it correct!'\n",
    "translation = translator(text)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако для русского языка простой pipeline не сработает.\n",
    "Для этой задачи надо сделать кастомный pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ab3e5b8a444d77bac6e406bde7ae94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02acfd8c9df42a6b9a545a8a46caaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12da591a7923490f893edddf734ffe6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ce6b516ba448058beabca066d23874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/803k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd32bcfecbfa47548ff258799e9f6294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61386495cbb4d05af0aaefb77267ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-ru-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ru-en')\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's me and I going to show you how to do it right!\n",
      "CPU times: user 1min 46s, sys: 2.18 s, total: 1min 48s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = 'Привет! Это я и я собираюсь показать вам как делать это правильно!'\n",
    "tokenized_text = tokenizer.prepare_seq2seq_batch([text])\n",
    "translation = model.generate(**tokenized_text)\n",
    "translation_text = tokenizer.batch_decode(translation, skip_special_tokens=True)[0]\n",
    "print(translation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dostoevsky = \"\"\"\n",
    "                В конце ноября, в оттепель, часов в девять утра, поезд Петербургско-Варшавской железной дороги на всех парах подходил к Петербургу. Было так сыро и туманно, что насилу рассвело; в десяти шагах, вправо и влево от дороги, трудно было разглядеть хоть что-нибудь из окон вагона. Из пассажиров были и возвращавшиеся из-за границы; но более были наполнены отделения для третьего класса, и все людом мелким и деловым, не из очень далека. Все, как водится, устали, у всех отяжелели за ночь глаза, все назяблись, все лица были бледножелтые, под цвет тумана.\n",
    "\n",
    "В одном из вагонов третьего класса, с рассвета, очутились друг против друга, у самого окна, два пассажира, - оба люди молодые, оба почти налегке, оба не щегольски одетые, оба с довольно замечательными физиономиями, и оба пожелавшие, наконец, войти друг с другом в разговор. Если б они оба знали один про другого, чем они особенно в эту минуту замечательны, то, конечно, подивились бы, что случай так странно посадил их друг против друга в третьеклассном вагоне петербургско-варшавского поезда. Один из них был небольшого роста, лет двадцати семи, курчавый и почти черноволосый, с серыми, маленькими, но огненными глазами. Нос его был широки сплюснут, лицо скулистое; тонкие губы беспрерывно складывались в какую-то наглую, насмешливую и даже злую улыбку; но лоб его был высок и хорошо сформирован и скрашивал неблагородно развитую нижнюю часть лица. Особенно приметна была в этом лице его мертвая бледность, придававшая всей физиономии молодого человека изможденный вид, несмотря на довольно крепкое сложение, и вместе с тем что-то страстное, до страдания, не гармонировавшее с нахальною и грубою улыбкой и с резким, самодовольным его взглядом. Он был тепло одет, в широкий, мерлушечий, черный, крытый тулуп, и за ночь не зяб, тогда как сосед его принужден был вынести на своей издрогшей спине всю сладость сырой, ноябрьской русской ночи, к которой, очевидно, был не приготовлен. На нем был довольно широкий и толстый плащ без рукавов и с огромным капюшоном, точь-в-точь как употребляют часто дорожные, по зимам, где-нибудь далеко за границей, в Швейцарии, или, например, в Северной Италии, не рассчитывая, конечно, при этом и на такие концы по дороге, как от Эйдкунена до Петербурга. Но что годилось и вполне удовлетворяло в Италии, то оказалось не совсем пригодным в России. Обладатель плаща с капюшоном был молодой человек, тоже лет двадцати шести или двадцати семи, роста немного повыше среднего, очень белокур, густоволос, со впалыми щеками и с легонькою, востренькою, почти совершенно белою бородкой. Глаза его были большие, голубые и пристальные; во взгляде их было что-то тихое, но тяжелое, что-то полное того странного выражения, по которому некоторые угадывают с первого взгляда в субъекте падучую болезнь. Лицо молодого человека было, впрочем, приятное, тонкое и сухое, но бесцветное, а теперь даже до-синя иззябшее. В руках его болтался тощий узелок из старого, полинялого фуляра, заключавший, кажется, все его дорожное достояние. На ногах его были толстоподошвенные башмаки с штиблетами, - все не по-русски. Черноволосый сосед в крытом тулупе все это разглядел, частию от нечего делать, и, наконец, спросил с тою неделикатною усмешкой, в которой так бесцеремонно и небрежно выражается иногда людское удовольствие при неудачах ближнего:\n",
    "\n",
    "- Зябко?\n",
    "\n",
    "И повел плечами.\n",
    "\n",
    "- Очень, - ответил сосед с чрезвычайною готовностью, - и заметьте, это еще оттепель. Что ж, если бы мороз? Я даже не думал, что у нас так холодно. Отвык.\n",
    "\n",
    "- Из-за границы что ль?\n",
    "\n",
    "- Да, из Швейцарии.\n",
    "\n",
    "- Фью! Эк ведь вас!..\n",
    "\n",
    "Черноволосый присвистнул и захохотал.\n",
    "\n",
    "Завязался разговор. Готовность белокурого молодого человека в швейцарском плаще отвечать на все вопросы своего черномазого соседа была удивительная и без всякого подозрения совершенной небрежности, неуместности и праздности иных вопросов. Отвечая, он объявил, между прочим, что действительно долго не был в России, слишком четыре года, что отправлен был за границу по болезни, по какой-то странной нервной болезни, в роде падучей или Виттовой пляски, каких-то дрожаний и судорог. Слушая его, черномазый несколько раз усмехался; особенно засмеялся он, когда на вопрос: \"что же, вылечили?\" - белокурый отвечал, что \"нет, не вылечили\".\n",
    "\n",
    "- Хе! Денег что, должно быть, даром переплатили, а мы-то им здесь верим, - язвительно заметил черномазый.\n",
    "\n",
    "- Истинная правда! - ввязался в разговор один сидевший рядом и дурно одетый господин, нечто в роде закорузлого в подьячестве чиновника, лет сорока, сильного сложения, с красным носом и угреватым лицом: - истинная правда-с, только все русские силы даром к себе переводят!\n",
    "\n",
    "- О, как вы в моем случае ошибаетесь, - подхватил швейцарский пациент, тихим и примиряющим голосом; - конечно, я спорить не могу, потому что всего не знаю, но мой доктор мне из своих последних еще на дорогу сюда дал, да два почти года там на свой счет содержал.\n",
    "\n",
    "- Что ж, некому платить что ли было? - спросил черномазый.\n",
    "\n",
    "- Да, господин Павлищев, который меня там содержал, два года назад помер; я писал потом сюда генеральше Епанчиной, моей дальней родственнице, но ответа не получил. Так с тем и приехал.\n",
    "\n",
    "- Куда же приехали-то?\n",
    "\n",
    "- То-есть, где остановлюсь?.. Да не знаю еще, право… так…\n",
    "\n",
    "- Не решились еще?\n",
    "\n",
    "И оба слушателя снова захохотали.\n",
    "\n",
    "- И небось в этом узелке вся ваша суть заключается? - спросил черномазый.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3704: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/tf_utils.py:1800: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of November, in the throes, at nine o'clock in the morning, the Petersburg-Warshav railway train on all the pairs approached Petersburg. It was so damp and foggy that his eyes were so thin; ten feet to the right and to the left of the road, it was hard to see anything out of the windows of the wagon grudgingly. Out of the passengers came back from abroad; but they were filled with branches for the third class, and all men were very small and business, not very far apart. Everything was out of the blue, tired, all over the night, all eyes were heavy, all the faces were pale, all the faces were pale, were in the colour of the fog. In one of the third class wagons, out of the sun, came out against each other, out of the height of the window, two passengers, both of them were young, both of them were easy, both of them were not lightly dressed, both of them were rather stunned in the night, all of them, all of them were pale, all of them were pale, finally in the colours, in one of them, out of the other countries, out of the sun, out of the passengers, out of us, out of the two passengers, out of the two passengers, both were both of the young, both, both of the young, both of the light, both was light, both was a man, both light, both light, both, both was light, both, both, both of the man, both was light, both, both, both was light, both, both, both were not light, both, both of the same in the same in the same in the same in one in the same in the same in the same in the same in the same in the same in the same in the same in the same in the same in the same in the other.\n",
      "CPU times: user 1min 47s, sys: 2.11 s, total: 1min 49s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = dostoevsky\n",
    "tokenized_text = tokenizer.prepare_seq2seq_batch([text])\n",
    "translation = model.generate(**tokenized_text)\n",
    "translation_text = tokenizer.batch_decode(translation, skip_special_tokens=True)[0]\n",
    "print(translation_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "Решение рабочее, но для прода применять такое не возможно, так как скорость работы просто \"никакая\" цифры говорят сами за себя."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
